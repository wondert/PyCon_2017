{"nbformat_minor": 1, "cells": [{"source": "# Redcard Exploratory Data Analysis\n\nThis dataset is taken from a fantastic paper that looks to see how analytical choices made by different data science teams on the same dataset in an attempt to answer the same research question affect the final outcome.\n\n[Many analysts, one dataset: Making transparent how variations in analytical choices affect results](https://osf.io/gvm2z/)\n\nThe data can be found [here](https://osf.io/47tnc/).\n\n", "cell_type": "markdown", "metadata": {}}, {"source": "## The Task\n\nDo an Exploratory Data Analysis on the redcard dataset. Keeping in mind the question is the following: **Are soccer referees more likely to give red cards to dark-skin-toned players than light-skin-toned players?**\n\n- Before plotting/joining/doing something, have a question or hypothesis that you want to investigate\n- Draw a plot of what you want to see on paper to sketch the idea\n- Write it down, then make the plan on how to get there\n- How do you know you aren't fooling yourself\n- What else can I check if this is actually true?\n- What evidence could there be that it's wrong?\n", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nfrom __future__ import absolute_import, division, print_function\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import GridSpec\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport os, sys\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set_context(\"poster\", font_scale=1.3)\n\nimport missingno as msno\nimport pandas_profiling\n\nfrom sklearn.datasets import make_blobs\nimport time", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## About the Data\n\n> The dataset is available as a list with 146,028 dyads of players and referees and includes details from players, details from referees and details regarding the interactions of player-referees. A summary of the variables of interest can be seen below. A detailed description of all variables included can be seen in the README file on the project website. \n\n> From a company for sports statistics, we obtained data and profile photos from all soccer players (N = 2,053) playing in the first male divisions of England, Germany, France and Spain in the 2012-2013 season and all referees (N = 3,147) that these players played under in their professional career (see Figure 1). We created a dataset of player\u00e2\u0080\u0093referee dyads including the number of matches players and referees encountered each other and our dependent variable, the number of red cards given to a player by a particular referee throughout all matches the two encountered each other.\n\n> -- https://docs.google.com/document/d/1uCF5wmbcL90qvrk_J27fWAvDcDNrO9o_APkicwRkOKc/edit\n\n\n| Variable Name: | Variable Description: | \n| -- | -- | \n| playerShort | short player ID | \n| player | player name | \n| club | player club | \n| leagueCountry | country of player club (England, Germany, France, and Spain) | \n| height | player height (in cm) | \n| weight | player weight (in kg) | \n| position | player position | \n| games | number of games in the player-referee dyad | \n| goals | number of goals in the player-referee dyad | \n| yellowCards | number of yellow cards player received from the referee | \n| yellowReds | number of yellow-red cards player received from the referee | \n| redCards | number of red cards player received from the referee | \n| photoID | ID of player photo (if available) | \n| rater1 | skin rating of photo by rater 1 | \n| rater2 | skin rating of photo by rater 2 | \n| refNum | unique referee ID number (referee name removed for anonymizing purposes) | \n| refCountry | unique referee country ID number | \n| meanIAT | mean implicit bias score (using the race IAT) for referee country | \n| nIAT | sample size for race IAT in that particular country | \n| seIAT | standard error for mean estimate of race IAT   | \n| meanExp | mean explicit bias score (using a racial thermometer task) for referee country | \n| nExp | sample size for explicit bias in that particular country | \n| seExp |  standard error for mean estimate of explicit bias measure | \n\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def save_subgroup(dataframe, g_index, subgroup_name, prefix='raw_'):\n    save_subgroup_filename = \"\".join([prefix, subgroup_name, \".csv.gz\"])\n    dataframe.to_csv(save_subgroup_filename, compression='gzip', encoding='UTF-8')\n    test_df = pd.read_csv(save_subgroup_filename, compression='gzip', index_col=g_index, encoding='UTF-8')\n    # Test that we recover what we send in\n    if dataframe.equals(test_df):\n        print(\"Test-passed: we recover the equivalent subgroup dataframe.\")\n    else:\n        print(\"Warning -- equivalence test!!! Double-check.\")", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "def load_subgroup(filename, index_col=[0]):\n    return pd.read_csv(filename, compression='gzip', index_col=index_col)", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Tidy Dyads and Starting Joins", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "clean_players = load_subgroup(\"../data/redcard/cleaned_players.csv.gz\")\nplayers = load_subgroup(\"../data/redcard/raw_players.csv.gz\", )\ncountries = load_subgroup(\"../data/redcard/raw_countries.csv.gz\")\nreferees = load_subgroup(\"../data/redcard/raw_referees.csv.gz\")\nagg_dyads = pd.read_csv(\"../data/redcard/raw_dyads.csv.gz\", compression='gzip', index_col=[0, 1])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "agg_dyads.head()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "# Test if the number of games is equal to the victories + ties + defeats in the dataset", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "all(agg_dyads['games'] == agg_dyads.victories + agg_dyads.ties + agg_dyads.defeats)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "# Sanity check passes", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "len(agg_dyads.reset_index().set_index('playerShort'))", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "agg_dyads['totalRedCards'] = agg_dyads['yellowReds'] + agg_dyads['redCards']\nagg_dyads.rename(columns={'redCards': 'strictRedCards'}, inplace=True)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "agg_dyads.head()", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Remove records that come from players who don't have a skintone rating\n\nThere are a couple of ways to do this -- set operations and joins are two ways demonstrated below: ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "clean_players.head()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "player_dyad = (clean_players.merge(agg_dyads.reset_index().set_index('playerShort'),\n                                   left_index=True,\n                                   right_index=True))", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "player_dyad.head()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "clean_dyads = (agg_dyads.reset_index()[agg_dyads.reset_index()\n                                   .playerShort\n                                   .isin(set(players.index))\n                                  ]).set_index(['refNum', 'playerShort'])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "clean_dyads.shape, agg_dyads.shape, player_dyad.shape", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "clean_dyads.head()", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Disaggregate\n\nThe dyads are currently an aggregated metric summarizing all times a particular referee-player pair play were matched. To properly handle the data, we have to disaggregate the data into a tidy/long format. This means that each game is a row.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# inspired by https://github.com/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb\ncolnames = ['games', 'totalRedCards']\nj = 0\nout = [0 for _ in range(sum(clean_dyads['games']))]\n\nfor index, row in clean_dyads.reset_index().iterrows():\n    n = row['games']\n    d = row['totalRedCards']\n    ref = row['refNum']\n    player = row['playerShort']\n    for _ in range(n):\n        row['totalRedCards'] = 1 if (d-_) > 0 else 0\n        rowlist=list([ref, player, row['totalRedCards']])\n        out[j] = rowlist\n        j += 1\n\ntidy_dyads = pd.DataFrame(out, columns=['refNum', 'playerShort', 'redcard'],).set_index(['refNum', 'playerShort'])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "# 3092\ntidy_dyads.redcard.sum()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "# Notice this is longer than before\nclean_dyads.games.sum()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "tidy_dyads.shape", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "# Ok, this is a bit crazy... tear it apart and figure out what each piece is doing if it's not clear\nclean_referees = (referees.reset_index()[referees.reset_index()\n                                                 .refNum.isin(tidy_dyads.reset_index().refNum\n                                                                                       .unique())\n                                        ]).set_index('refNum')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "clean_referees.shape, referees.shape", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "clean_countries = (countries.reset_index()[countries.reset_index()\n                                           .refCountry\n                                           .isin(clean_referees.refCountry\n                                                 .unique())\n                                          ].set_index('refCountry'))", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "clean_countries.shape, countries.shape", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "tidy_dyads.head()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "tidy_dyads.to_csv(\"../data/redcard/cleaned_dyads.csv.gz\", compression='gzip')", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.1", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "anaconda-cloud": {}}}